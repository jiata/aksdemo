{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Driver\n",
    "\n",
    "In this notebook, we will develop the API that will call our model. This module initializes the model, transforms the input so that it is in the appropriate format and defines the scoring method that will produce the predictions. The API will expect the input to be in JSON format. Once a request is received, the API will convert the json encoded request body into the image format. There are two main functions in the API: init() and run(). The init() function loads the model and returns a scoring function. The run() function process the images and uses the first function to score them.\n",
    "\n",
    "    Note: Always make sure you don't have any lingering notebooks running (Shutdown previous notebooks). Otherwise it may cause GPU memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from dotenv import set_key, find_dotenv\n",
    "import logging\n",
    "from testing_utilities import get_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Deep learning libraries\n",
    "from fastai.vision import open_image, load_learner\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"FastAI: \", fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%writefile driver.py\n",
    "# Driver for Model  \n",
    "\n",
    "import timeit as t\n",
    "import logging\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "from fastai.vision import open_image, load_learner\n",
    "from azureml.contrib.services.aml_request import rawhttp\n",
    "from azureml.core.model import Model\n",
    "from toolz import compose\n",
    "\n",
    "\n",
    "def _create_scoring_func():\n",
    "    \"\"\" Initialize ResNet 18 Model\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    start = t.default_timer()\n",
    "    model_name = \"resnet_model\"\n",
    "    model_path = Model.get_model_path(model_name=model_name)\n",
    "    model_dir_path, model_filename = os.path.split(model_path)\n",
    "    model = load_learner(path=model_dir_path, fname=model_filename)\n",
    "    end = t.default_timer()\n",
    "\n",
    "    loadTimeMsg = \"Model loading time: {0} ms\".format(round((end - start) * 1000, 2))\n",
    "    logger.info(loadTimeMsg)\n",
    "\n",
    "    def call_model(img_ref):\n",
    "        img = open_image(img_ref)\n",
    "        pred_class, pred_idx, outputs = model.predict(img)\n",
    "        decoded_predictions = [str(pred_class), outputs[pred_idx].item()]\n",
    "        return [decoded_predictions]\n",
    "\n",
    "    return call_model\n",
    "\n",
    "\n",
    "def get_model_api():\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    scoring_func = _create_scoring_func()\n",
    "\n",
    "    def process_and_score(images_dict):\n",
    "        \"\"\" Classify the input using the loaded model\n",
    "        \"\"\"\n",
    "        start = t.default_timer()\n",
    "        logger.info(\"Scoring {} images\".format(len(images_dict)))\n",
    "        preds = {key: scoring_func(img_ref) for key, img_ref in images_dict.items()}\n",
    "        end = t.default_timer()\n",
    "\n",
    "        logger.info(\"Predictions: {0}\".format(preds))\n",
    "        logger.info(\"Predictions took {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "        return (preds, \"Computed in {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "\n",
    "    return process_and_score\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\" Initialise the model and scoring function\n",
    "    \"\"\"\n",
    "    global process_and_score\n",
    "    process_and_score = get_model_api()\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    \"\"\" Make a prediction based on the data passed in using the preloaded model\n",
    "    \"\"\"\n",
    "    return process_and_score(request.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Test the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# We test the driver by passing data.\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "%run driver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Let's load the workspace.\n",
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_path = Model.get_model_path(\"resnet_model\", _workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always make sure you don't have any lingering notebooks running. Otherwise it may cause GPU memory issue.\n",
    "process_and_score = get_model_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "resp = process_and_score({\"lynx\": open(\"220px-Lynx_lynx_poing.jpg\", \"rb\")})\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory \n",
    "torch.cuda.empty_cache()# Next, we will [build a docker image with this modle driver and other supporting files](03_BuildImage.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
