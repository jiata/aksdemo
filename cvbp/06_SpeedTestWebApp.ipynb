{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test deployed web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls some images and tests them against the deployed web application. We submit requests asychronously which should reduce the contribution of latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from timeit import default_timer\n",
    "\n",
    "import aiohttp\n",
    "import matplotlib.pyplot as plt\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.workspace import Workspace\n",
    "from dotenv import get_key, find_dotenv\n",
    "from testing_utilities import to_img, gen_variations_of_one_image, get_auth\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aiohttp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrive the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service_name = get_key(env_path, 'aks_service_name')\n",
    "aks_service = AksWebservice(ws, name=aks_service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our deployed service with 100 calls. We will only have 4 requests concurrently at any time. We have only deployed one pod on one node and increasing the number of concurrent calls does not really increase throughput. Feel free to try different values and see how the service responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_REQUESTS = 100  # Total number of requests\n",
    "CONCURRENT_REQUESTS = 4   # Number of requests at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring URL and API key of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = aks_service.scoring_uri\n",
    "api_key = aks_service.get_keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg\"\n",
    "plt.imshow(to_img(IMAGEURL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use varitions of the same image to test the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [[scoring_url, img_bytes] for img_bytes in gen_variations_of_one_image(IMAGEURL, NUMBER_OF_REQUESTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(result):\n",
    "    return json.loads(result.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(url, session, data, headers):\n",
    "    start_time = default_timer()\n",
    "    async with session.request('post', url, data={'image':data}, headers=headers) as response:\n",
    "        resp = await response.read()\n",
    "        elapsed = default_timer() - start_time\n",
    "        return resp, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def bound_fetch(sem, url, session, data, headers):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        return await fetch(url, session, data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def await_with_progress(coros):\n",
    "    results=[]\n",
    "    for f in tqdm(asyncio.as_completed(coros), total=len(coros)):\n",
    "        result = await f\n",
    "        results.append((decode(result[0]),result[1]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run(url_list, num_concurrent=CONCURRENT_REQUESTS):\n",
    "    # headers = {'content-type': 'application/json'}\n",
    "    headers = {'Authorization':('Bearer '+ api_key)}\n",
    "    tasks = []\n",
    "    # create instance of Semaphore\n",
    "    sem = asyncio.Semaphore(num_concurrent)\n",
    "\n",
    "    # Create client session that will ensure we dont open new connection\n",
    "    # per each request.\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for url, data in url_list:\n",
    "            # pass Semaphore and session to every POST request\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session, data, headers))\n",
    "            tasks.append(task)\n",
    "        return await await_with_progress(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we run the 100 requests against our deployed service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "start_time = default_timer()\n",
    "complete_responses = loop.run_until_complete(asyncio.ensure_future(run(url_list, num_concurrent=CONCURRENT_REQUESTS)))\n",
    "elapsed = default_timer() - start_time\n",
    "print('Total Elapsed {}'.format(elapsed))\n",
    "print('Avg time taken {0:4.2f} ms'.format(1000*elapsed/len(url_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_responses[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_succesful=[i[0][0]['image'][0][0] for i in complete_responses].count('n02127052')\n",
    "print('Succesful {} out of {}'.format(num_succesful, len(url_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example response\n",
    "plt.imshow(to_img(IMAGEURL))\n",
    "complete_responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tear down the cluster and all related resources go to the [tear down the cluster](07_TearDown.ipynb) notebook."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
